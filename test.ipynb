{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR = \"./test/\"\n",
    "model_path = './model_train_epoch_10.pth'\n",
    "TEST_PKL = './test_paired_dict.pkl'\n",
    "VAL_PKL = './val_paired_dict.pkl'\n",
    "MLB_PKL = './mlb.pkl'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 16\n",
    "THRESHOLD = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_path(img_id):\n",
    "    \n",
    "    img_path = DIR + [*img_id][0] + '/' + [*img_id][1] + '/' + [*img_id][2] + '/' + [*img_id][3] + '/' + img_id\n",
    "    return img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id, ingredients = [*self.data_dict.items()][idx]\n",
    "        image_path = get_img_path(image_id)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        ingredients_tensor = torch.tensor(ingredients)\n",
    "        return image, ingredients_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgData(Dataset):\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.img_path\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_ingredients = 440\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_in_features, num_unique_ingredients)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_PKL, 'rb') as file:    \n",
    "    test_paired_dict = pickle.load(file)\n",
    "with open(VAL_PKL, 'rb') as file:\n",
    "    val_paired_dict = pickle.load(file)\n",
    "\n",
    "with open(MLB_PKL, 'rb') as file:\n",
    "    mlb = pickle.load(file)\n",
    "\n",
    "\n",
    "test_set = MyDataset(test_paired_dict, transform=preprocess)\n",
    "val_set = MyDataset(val_paired_dict, transform=preprocess)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(targets_idx, pred_idx):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "            \n",
    "    for a,b in zip(targets_idx, pred_idx):\n",
    "        targets_label = set(mlb.classes_[a])\n",
    "        pred_label = set(mlb.classes_[b])\n",
    "        intersection = targets_label.intersection(pred_label)\n",
    "        pred_only = pred_label - intersection\n",
    "        target_only = targets_label - intersection\n",
    "        tp = len(intersection)\n",
    "        fp = len(pred_only)\n",
    "        fn = len(target_only)\n",
    "        tn = num_unique_ingredients - (tp + fp + fn)\n",
    "        accuracy.append((tp + tn) / (tp + fp + fn + tn))\n",
    "        precision.append(tp / (tp + fp) if tp + fp != 0 else 0)\n",
    "        recall.append(tp / (tp + fn) if tp + fn != 0 else 0)\n",
    "        f1.append(2 * tp / (2 * tp + fp + fn) if tp + fp + fn != 0 else 0)\n",
    "    return np.average(accuracy), np.average(precision), np.average(recall), np.average(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test(data_set, batch_size=BATCH_SIZE, threshold = THRESHOLD):\n",
    "        \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    acc_ls = []\n",
    "    pre_ls = []\n",
    "    rec_ls = []\n",
    "    f1_ls = []\n",
    "    val_loader = DataLoader(dataset=data_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    # Disable gradient calculation to speed up inference\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        with tqdm(val_loader, desc=f'Validation', unit='batch') as tqdm_loader:\n",
    "            for val_data in tqdm_loader:\n",
    "                val_inputs, val_labels = val_data\n",
    "                \n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_labels = val_labels.to(device).float()\n",
    "                \n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                \n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                val_running_loss += val_loss.item()\n",
    "                \n",
    "                val_outputs = torch.sigmoid(val_outputs)\n",
    "                values = val_outputs.cpu().view(-1).numpy()\n",
    "                \n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.hist(values, bins=50, color='blue', alpha=0.7)\n",
    "                plt.title('Distribution of Tensor Values')\n",
    "                plt.xlabel('Value')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.grid(True)\n",
    "                plt.savefig('./distribution.png')\n",
    "                plt.show()\n",
    "                \n",
    "\n",
    "                \n",
    "                targets_idx = [[idx for idx, col in enumerate(row) if col == 1] for row in val_labels.cpu()]\n",
    "                pred_idx = [[idx for idx, col in enumerate(row) if col >= threshold] for row in val_outputs.cpu()]\n",
    "                \n",
    "                avg_accuracy, avg_precision, avg_recall, avg_f1 = calc_scores(targets_idx, pred_idx)\n",
    "                acc_ls.append(avg_accuracy)\n",
    "                pre_ls.append(avg_precision)\n",
    "                rec_ls.append(avg_recall)\n",
    "                f1_ls.append(avg_f1)\n",
    "                \n",
    "                mean=[0.485, 0.456, 0.406]\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "                unnormalize = transforms.Normalize(mean=[-m/s for m, s in zip(mean, std)], std=[1/s for s in std])\n",
    "                unnormalized_img_tensor = unnormalize(val_inputs)[0]\n",
    "                unnormalized_tensor = torch.clamp(unnormalized_img_tensor, 0, 1)\n",
    "                to_pil = transforms.ToPILImage()\n",
    "                #image = to_pil(unnormalized_tensor) \n",
    "                #plt.axis('off')\n",
    "                #plt.imshow(image)\n",
    "                \n",
    "                tqdm_loader.set_postfix(accuracy=avg_accuracy, precision=avg_precision, recall=avg_recall, f1=avg_f1)\n",
    "\n",
    "    accuracy = np.average(acc_ls) \n",
    "    precision = np.average(pre_ls)\n",
    "    recall = np.average(rec_ls)\n",
    "    f1 = np.average(f1_ls)\n",
    "\n",
    "    #print(f\"Validation Loss: {val_loss}, Accuracy: {val_accuracy}%\")\n",
    "    print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}, Threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img_path, batch_size=1, threshold =THRESHOLD):\n",
    "    test_loader = DataLoader(ImgData(img_path, transform=preprocess), batch_size=1)\n",
    "    for test_data in test_loader:\n",
    "        test_inputs = test_data\n",
    "        test_inputs = test_inputs.to(device)\n",
    "        test_outputs = model(test_inputs)\n",
    "        test_outputs = torch.sigmoid(test_outputs)\n",
    "        targets_idx = [[idx for idx, col in enumerate(row) if col >= threshold] for row in test_outputs.cpu()]\n",
    "        return [mlb.classes_[idx] for idx in targets_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_values = [0.1 + i * 0.05 for i in range(11)]\n",
    "for thv in threshold_values:\n",
    "    val_test(val_set, threshold=thv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_values = [0.1 + i * 0.05 for i in range(11)]\n",
    "for thv in threshold_values:\n",
    "    val_test(test_set, threshold=thv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = \"./test_image.jpg\"\n",
    "labels = test(test_img, batch_size=BATCH_SIZE, threshold =THRESHOLD)\n",
    "label_string = \", \".join(labels)\n",
    "print(f\"The food in the image contains: {label_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on validation, batchsize = 16\n",
    "thresholds = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "precision_scores = [0.32, 0.39, 0.42, 0.47, 0.52, 0.54, 0.56, 0.56, 0.55, 0.48, 0.28]\n",
    "recall_scores = [0.65, 0.57, 0.50, 0.44, 0.40, 0.35, 0.31, 0.27, 0.22, 0.18, 0.06]\n",
    "f1_scores = [0.41, 0.46, 0.45, 0.45, 0.42, 0.40, 0.37, 0.33, 0.29, 0.25, 0.10]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(thresholds, precision_scores, marker='o', label='Precision')\n",
    "plt.plot(thresholds, recall_scores, marker='s', label='Recall')\n",
    "plt.plot(thresholds, f1_scores, marker='d', label='F1 Score')\n",
    "\n",
    "plt.title('Precision, Recall, and F1 Score vs. Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds)\n",
    "plt.savefig('./val_scores.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test, batchsize = 16\n",
    "thresholds = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "precision = [0.316, 0.388, 0.446, 0.492, 0.526, 0.552, 0.567, 0.566, 0.552, 0.519, 0.466]\n",
    "recall = [0.666, 0.589, 0.526, 0.472, 0.422, 0.375, 0.330, 0.284, 0.240, 0.195, 0.150]\n",
    "f1_score = [0.413, 0.450, 0.462, 0.458, 0.443, 0.419, 0.389, 0.351, 0.310, 0.262, 0.211]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(thresholds, precision_scores, marker='o', label='Precision')\n",
    "plt.plot(thresholds, recall_scores, marker='s', label='Recall')\n",
    "plt.plot(thresholds, f1_scores, marker='d', label='F1 Score')\n",
    "\n",
    "plt.title('Precision, Recall, and F1 Score vs. Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds)\n",
    "plt.savefig('./test_scores.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
