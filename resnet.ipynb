{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file path\n",
    "#json_path = './recipe_1m_ingredients_extracted.json'\n",
    "all_json_path = './1mtest_all_440_labels.json'\n",
    "train_json_path = './1mtest_train_440_labels.json'\n",
    "test_json_path = './1mtest_test_440_labels.json'\n",
    "val_json_path = './1mtest_val_440_labels.json'\n",
    "\n",
    "# Open the JSON file\n",
    "#with open(json_path, 'r') as file:\n",
    "    #json_data = json.load(file)\n",
    "\n",
    "with open(all_json_path, 'r') as file:\n",
    "    all_json_data = json.load(file)\n",
    "    \n",
    "with open(train_json_path, 'r') as file:\n",
    "    train_json_data = json.load(file)\n",
    "\n",
    "with open(test_json_path, 'r') as file:\n",
    "    test_json_data = json.load(file)\n",
    "\n",
    "with open(val_json_path, 'r') as file:\n",
    "    val_json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get set of unique ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_ingredients(all_data):\n",
    "    unique_ingredients = set()\n",
    "    ing_dict = {key: np.array(val) for key, val in all_data['cleaned_ingredients'].items()}\n",
    "    for val in ing_dict.values():\n",
    "        unique_ingredients.update(val)\n",
    "    return np.array(list(unique_ingredients))\n",
    "\n",
    "def get_ingredients_lists(all_data):\n",
    "    ing_dict = {key: np.array(val) for key, val in all_data['cleaned_ingredients'].items()}\n",
    "    return ing_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get unique ingredients set from all_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ingredients = get_unique_ingredients(all_json_data)\n",
    "ing_lists = get_ingredients_lists(all_json_data)\n",
    "mlb = preprocessing.MultiLabelBinarizer()\n",
    "mlb.fit(ing_lists)\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "ohe.fit(unique_ingredients.reshape(-1, 1))\n",
    "pickle.dump(mlb, open('mlb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute max label length for sklearn.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_len(label_dict):\n",
    "    max_len = 0\n",
    "    for labels in label_dict.values():\n",
    "        max_len = max(max_len, len(labels))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def label_padding(label_dict, max_len):\n",
    "    for key, val in label_dict.items():\n",
    "        label_dict[key] = val + ['<pad>'] * (max_len - len(val))\n",
    "    return label_dict\n",
    "'''\n",
    "def label_padding(label_dict, max_len):\n",
    "    for key, val in label_dict.items():\n",
    "        label_dict[key] = np.pad(val, (0, max_len - len(val)), 'constant', constant_values=-1)\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingredients from str to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def str2num_le(str_dict):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    unique_ingredients = get_unique_ingredients(str_dict)\n",
    "    le.fit(list(unique_ingredients))\n",
    "    for key, val in str_dict.items():\n",
    "        str_dict[key] = np.array(le.transform(list(val)))\n",
    "    return str_dict,le\n",
    "\n",
    "def str2num_ohe(str_dict, encoder):\n",
    "    for key, value in str_dict.items():\n",
    "        str_dict[key] = encoder.transform(np.array(value).reshape(-1, 1)).toarray()\n",
    "    return str_dict\n",
    "\n",
    "def str2num(str_dict, encoder):\n",
    "    num_dict = {}\n",
    "    key_arr = np.array(list(str_dict.keys()))\n",
    "    val_arr = []\n",
    "    for val in str_dict.values():\n",
    "        val_arr.append(val)\n",
    "    val_arr = encoder.transform(val_arr)\n",
    "    for k in range(len(key_arr)):\n",
    "        num_dict[key_arr[k]] = val_arr[k]\n",
    "    return num_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get image path from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_path(img_id):\n",
    "    dir = \"./test/\"\n",
    "    img_path = dir + [*img_id][0] + '/' + [*img_id][1] + '/' + [*img_id][2] + '/' + [*img_id][3] + '/' + img_id\n",
    "    return img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries, convertit into a desired structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paired_dict(json_data):\n",
    "    #ingredient_dict = json_data['extracted ingredients']\n",
    "    ing_dict = json_data['cleaned_ingredients']\n",
    "    image_dict = json_data['image_file_name_ls']\n",
    "\n",
    "    # Method to make the ingredient dict in the form of string: list of strings\n",
    "    #def list_of_dicts_to_array(dict_list):\n",
    "        #return np.array([d['text'] for d in dict_list])\n",
    "\n",
    "    #convert the ingredients dict\n",
    "    #ingredient_dict = {key: list_of_dicts_to_array(val) for key, val in ingredient_dict.items()}\n",
    "    #max_len = compute_max_len(ingredient_dict)\n",
    "    #ingredient_dict = label_padding(ingredient_dict, max_len)\n",
    "    #pair the image ids and ingredients\n",
    "    paired_dict = {}\n",
    "    assert len(image_dict) == len(ing_dict), \"The number of images and corresponding ingredients lists are not equal\"\n",
    "    \n",
    "    #ingredient_dict_le,le = str2num_le(ingredient_dict)\n",
    "    ing_dict = str2num(ing_dict, mlb)\n",
    "    for image_list, ingredient_list in zip(image_dict.values(), ing_dict.values()):\n",
    "        for image in image_list:\n",
    "            paired_dict[image] = ingredient_list\n",
    "    return paired_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paired_dict = get_paired_dict(train_json_data)\n",
    "test_paired_dict = get_paired_dict(test_json_data)\n",
    "val_paired_dict = get_paired_dict(val_json_data)\n",
    "for k,v in train_paired_dict.items():\n",
    "    print(k,len(v), np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_paired_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(train_paired_dict, file)\n",
    "with open('test_paired_dict.pkl', 'wb') as file:    \n",
    "    pickle.dump(test_paired_dict, file)\n",
    "with open('val_paired_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(val_paired_dict, file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_paired_dict.pkl', 'rb') as file:\n",
    "    train_paired_dict = pickle.load(file)\n",
    "with open('test_paired_dict.pkl', 'rb') as file:    \n",
    "    test_paired_dict = pickle.load(file)\n",
    "with open('val_paired_dict.pkl', 'rb') as file:\n",
    "    val_paired_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id, ingredients = [*self.data_dict.items()][idx]\n",
    "        image_path = get_img_path(image_id)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        ingredients_tensor = torch.tensor(ingredients)\n",
    "        return image, ingredients_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet to Extract Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA or not\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "# Load pre-trained ResNet model\n",
    "resnet = models.resnet50(pretrained=True).to(device)\n",
    "# Remove the classification layer\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "# Set model to evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "# Define image preprocessing transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(train_paired_dict, transform=preprocess)\n",
    "test_set = MyDataset(test_paired_dict, transform=preprocess)\n",
    "val_set = MyDataset(val_paired_dict, transform=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear CUDA Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_in_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_in_ftrs, len(unique_ingredients))\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    # Use tqdm to iterate over the training data with a progress bar\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as tqdm_loader:\n",
    "        for i, data in enumerate(tqdm_loader, 0):\n",
    "            # Get the inputs and labels from the data loader\n",
    "            inputs, labels = data\n",
    "            # Move inputs and labels to the device (e.g., GPU)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(inputs)\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Update the parameters by performing a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # Add the loss for this batch to the running loss\n",
    "            running_loss += loss.item()\n",
    "            # Update tqdm progress bar with current loss\n",
    "            tqdm_loader.set_postfix({'loss': loss.item()})\n",
    "    # Print average loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "    \n",
    "    # Save the model's state_dict after each epoch\n",
    "    torch.save(model.state_dict(), f'model_train_epoch_{epoch+1}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = resnet50\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "val_running_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "# Disable gradient calculation to speed up inference\n",
    "with torch.no_grad():\n",
    "    with tqdm(val_loader, desc=f'Validation', unit='batch') as tqdm_loader:\n",
    "        for val_data in tqdm_loader:\n",
    "            val_inputs, val_labels = val_data\n",
    "            \n",
    "            target_col = set()\n",
    "            for row in val_labels:\n",
    "                for col, value in enumerate(row):\n",
    "                    if value == 1:\n",
    "                        target_col.add(col)\n",
    "            \n",
    "            original_val_labels = val_labels\n",
    "            \n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device).float()\n",
    "            \n",
    "            #new_label = (val_labels == 1).sum(dim=0).cpu()\n",
    "            new_label = val_labels.cpu()\n",
    "            \n",
    "            comparison = torch.all(original_val_labels == new_label)\n",
    "            \n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "            \n",
    "            val_outputs = torch.sigmoid(val_outputs)\n",
    "            values = val_outputs.cpu().view(-1).numpy()\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "            val_running_loss += val_loss.item()\n",
    "            \n",
    "            \n",
    "            #print(torch.sum(prediction, dim=1))\n",
    "            \n",
    "            \n",
    "            #print('#>threshold:',torch.sum(val_outputs > threshold, dim=1))\n",
    "           \n",
    "            #'''\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(values, bins=50, color='blue', alpha=0.7)\n",
    "            plt.title('Distribution of Tensor Values')\n",
    "            plt.xlabel('Value')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            #'''\n",
    "            \n",
    "            predicted_col = set()\n",
    "            binary_pred = (val_outputs > 0.1).float()\n",
    "            for batch in binary_pred:\n",
    "                for idx, value in enumerate(batch):\n",
    "                    if value == 1:\n",
    "                        predicted_col.add(idx)\n",
    "                        \n",
    "            intersection = predicted_col.intersection(target_col)\n",
    "            pred_only = predicted_col - intersection\n",
    "            target_only = target_col - intersection\n",
    "            \n",
    "            tp = len(intersection)\n",
    "            fp = len(pred_only)\n",
    "            fn = len(target_only)\n",
    "            tn = len(unique_ingredients) - (tp + fp + fn)\n",
    "            \n",
    "            accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "            \n",
    "            predicted_label = mlb.classes_[list(predicted_col)]\n",
    "            target_label = mlb.classes_[list(target_col)]\n",
    "            \n",
    "            \n",
    "            mean=[0.485, 0.456, 0.406]\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            unnormalize = transforms.Normalize(mean=[-m/s for m, s in zip(mean, std)], std=[1/s for s in std])\n",
    "            unnormalized_img_tensor = unnormalize(val_inputs)[0]\n",
    "            unnormalized_tensor = torch.clamp(unnormalized_img_tensor, 0, 1)\n",
    "            to_pil = transforms.ToPILImage()\n",
    "            image = to_pil(unnormalized_tensor) \n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "            plt.imshow()\n",
    "            \n",
    "            tqdm_loader.set_postfix(accuracy=accuracy, precision=precision, recall=recall, f1=f1)\n",
    "            \n",
    "            #print(indices)\n",
    "            #for row in val_labels:\n",
    "                #print(row)\n",
    "            '''\n",
    "            # Calculate accuracy\n",
    "            #prediction = (val_outputs > threshold)\n",
    "            #val_total += val_labels.size(0)\n",
    "            #val_correct += ((prediction == val_labels).sum(dim=1) == val_labels.size(1)).sum().item()\n",
    "\n",
    "            tqdm_loader.set_postfix(val_loss=val_loss.item(), val_accuracy=(val_correct / val_total) * 100)\n",
    "            '''\n",
    "# Calculate validation loss and accuracy\n",
    "val_loss = val_running_loss / len(val_loader)\n",
    "val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "#print(f\"Validation Loss: {val_loss}, Accuracy: {val_accuracy}%\")\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "test_running_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "# Disable gradient calculation to speed up inference\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, desc=f'Testing', unit='batch') as tqdm_loader:\n",
    "        for test_data in tqdm_loader:\n",
    "            test_inputs, test_labels = test_data\n",
    "            test_inputs = test_inputs.to(device)\n",
    "            test_labels = test_labels.to(device).float()\n",
    "\n",
    "            test_outputs = model(test_inputs)\n",
    "            test_loss = criterion(test_outputs, test_labels)\n",
    "\n",
    "            test_running_loss += test_loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            test_total += test_labels.size(0)\n",
    "            test_correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "            tqdm_loader.set_postfix(test_loss=test_loss.item(), test_accuracy=(test_correct / test_total) * 100)\n",
    "\n",
    "# Calculate test loss and accuracy\n",
    "test_loss = test_running_loss / len(test_loader)\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss}, Accuracy: {test_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
